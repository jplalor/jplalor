---
title: "The Model Sets the Message"
---

Is AI is going to take your job?
It depends on what AI is good at.

Recently, researchers at Princeton, Penn, and NYU [calculated](https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4414065) risk scores for occupations that overlap highly with generative AI.
18 of the top-25 are post-secondary education.
"Business Teachers, Postsecondary" is number 22.

Hey, that's me!

Other occupations in the top-25 include Telemarketers (number 1), Sociologists, and Arbitrators, Mediators, and Conciliators. 

When [a similar study](https://doi-org.proxy.library.nd.edu/10.1016/j.techfore.2016.08.019) was done in the 2010s (using data from 2010), where was "Business Teachers, Postsecondary"?
Well, all Postsecondary Teachers were grouped together and ranked at 112.

The top-25 from the earlier study includes the following occupations (emphasis mine).

- Recreational *Therapists* (ranked number 1)
- First-Line *Supervisors* of Mechanics, Installers, and Repairers
- Physicians and Surgeons
- Lodging *Managers*

The older list includes many occupations that involve management, supervision, or intervention, either with employees or patients/clients. 
The new list is all about disseminating knowledge.

I think we have a bit of a Marshall McLuhan, "medium is the message," phenomenon going on here.
But in this case, the AI model sets the message in terms of public narrative.

In the 2010s, machine learning was abuzz, specifically supervised learning.
With supervised learning, an AI model observes large quantities of data that have explicit labels associated with them to learn a mapping between data inputs and those labels. 
Advancements were coming fast, especially on *structured* data.

So the thinking was, if supervised learning gets good enough, then a supervised model can look at historical structured data (medical records with a patient outcome, product defects with recommended fixes, etc.), and learn a mapping between input data and outputs, be they diseases classification, machine repairs, or anything in between. 

LLMs thrive on *unsupervised* learning with *unstructured* data.
And now we see professions that involve unstructured data and less easily defined tasks "at risk."
The AI advancement of the moment has significant influence on the discussion of job replacement. 
Looking back on Deep Blue, we have a more nuanced perspective than (I imagine) folks did at the time. 
