---
title: "Good, Fast, Cheap: How Many Can we Pick?"
---


> Good, fast, and cheap -- choose two.

This comes from an idea known as the [project management triangle](https://support.microsoft.com/en-us/office/the-project-triangle-8c892e06-d761-4d40-8e1f-17b33fdcf810).
Basically, if you want something done quickly, you need to compromise on quality or price. 
Same again if you want something done well, it'll either be slow or expensive. 

As should be clear by now, I'm going to look at this through an AI lens. 
Technology advancements often make things faster and cheaper, and can also improve quality. 
Especially lately, the push for "superhuman AI" is in part a way to make the "good" argument. 
If AI can do things fast and cheap, which is the going assumption, then the key argument is around how *good* it is.

There are two items that make this analysis too simplistic:

1. Obfuscation: AI at the moment is not cheap, nor is it fast. *Inference* is relatively cheap and fast. 
But training and fine-tuning these models is hugely expensive. 
And takes a very long time. 
The usual trends in decreasing cost of compute and training speed may apply, but these models have a long way to go before being cheap and fast. 
2. Moving goalposts: Firms want to make these models *good* based on their current expenses (again, these are not cheap, nor are they fast). 
In the meantime, people are going to get used to performance levels as they are, and the expectation of *good* will shift.
The goalposts of AI always move, and right now is no different. 
Even if technology advancements (aka buying new hardware -- aka dollars spent) make training these models cheap**er** and fast**er**, there will also be a relentless push to make them **better**.

So at the moment, it's hard to say if they are cheap, fast, or good? 
How much of the expense associated with this constant race to hit any of these marks will be borne by consumers? 


