---
title: "What's in a Name"
---


We're at an interesting moment culturally.
The notion of "AI" covers a very wide range of technological capabilities as well as projections for the future. 
In a sense, this isn't new.

There has always this fine line between "AI" and "just something that a computer can do" in the mind of the public. 
ELIZA, Deep Blue, Watson, even BERT. 
Now GPTs. 

Where things get interesting is when development of the current models hits a ceiling, and we have to look around for inspiration beyond *more data!*.
If you look at the table of contents for the go-to textbook on Artificial Intelligence ([link here](https://aima.cs.berkeley.edu/)), a lot of what fits in the general definition of AI today is squeezed into sections 5 and 6 of the book. 
There is a lot of AI that can be pulled in, maybe sooner rather than later, to address a lot of the issues seen with the current crop of GPTs. 

 