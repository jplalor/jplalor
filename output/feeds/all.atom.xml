<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>John Lalor</title><link href="http://jplalor.github.io/" rel="alternate"></link><link href="http://jplalor.github.io/feeds/all.atom.xml" rel="self"></link><id>http://jplalor.github.io/</id><updated>2019-02-21T00:00:00-05:00</updated><entry><title>Does Item Difficulty Affect DNN Performance?</title><link href="http://jplalor.github.io/emnlp-18.html" rel="alternate"></link><updated>2019-02-21T00:00:00-05:00</updated><author><name>John Lalor</name></author><id>tag:jplalor.github.io,2019-02-21:emnlp-18.html</id><summary type="html">&lt;p&gt;Short answer: yes.&lt;/p&gt;
&lt;p&gt;The long answer is a bit more involved, hence the blog post.
This post is a companion to our recent EMNLP 2018 paper &lt;a href="https://arxiv.org/abs/1702.04811"&gt;"Understanding Deep Learning Performance through an Examination of Test Set Difficulty: A Psychometric Case Study"&lt;/a&gt;.
If you're really interested, I have a recorded version of the talk from EMNLP on &lt;a href="https://www.youtube.com/watch?v=4FZYB-YvV7k"&gt;YouTube&lt;/a&gt;.&lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;In &lt;a href="http://jplalor.github.io/emnlp-16.html"&gt;an earlier post&lt;/a&gt; I discussed how Item Response Theory (IRT) can be used to build more advanced test sets for natural language processing models. 
IRT tests include items for which we know certain latent parameters such as difficulty and discriminatory ability.
Our previous work looked at using these test sets to, well, test a deep neural network to see if reported high accuracy scores were really indicative of high latent ability.
Turns out that high accuracy on a very easy dataset doesn't directly translate to high ability, which makes sense.
If the test is easy then most everyone will do well, so your high score isn't as impressive.
On the other hand, a high (but maybe not very high) score on a difficulty test does indicate high ability, because you have done well on a test that most find difficult. 
Knowing item difficulty and latent ability lets us better understand performance, of humans and of neural networks.&lt;/p&gt;
&lt;p&gt;The next question we wanted to answer was about the neural networks' performance on &lt;em&gt;specific&lt;/em&gt; items.
We determined how scores change at the aggregate level, but can we learn anything about a model's performance based on the difficulty of specific items?
Do high-performing models do better on easy items than low-performing models, or do they do better on harder items, or both?&lt;/p&gt;
&lt;h1&gt;The Goal&lt;/h1&gt;
&lt;p&gt;What we want to do here is determine if the latent difficulty of an item is predictive of whether a neural network model will label the item correctly.
Put another way: are easy items more likely to be labeled correctly by a neural network than harder items? 
And if so, does this relationship change as our models get better at the task? 
We already have data with item difficulties, from our prior work.
So these items are now our test set for the models that we will use.
Every model will label the IRT test set, and we can use these outputs and the input characteristics of the models to learn a logistic regression model to predict whether a model will label an item correctly, given some input set of features. &lt;/p&gt;
&lt;h1&gt;Different Data, Different model&lt;/h1&gt;
&lt;p&gt;How can we get a model that performs better or worse while maintaining the underlying structure so we can make meaningful comparisons?
One straightforward approach is to modify the training data, so that the same model can be trained with a variety of different training sets.
For a typical NLP task, there is some large data set that has been gathered and released to the research community.
It usually consists of a split between training, testing, and (sometimes) validation sets so that results can be compared between research groups.
When you build a new model, you use the entire training set to train your model, because more data is better and this will show the best possible performance for your model.
However, in our case we want a variety of performance levels, so to do that we can sample from the training set, and use this training subset to train several different models to label our IRT items. &lt;/p&gt;
&lt;h1&gt;Predicting Correctness&lt;/h1&gt;
&lt;p&gt;We know the output we want to predict: whether a given model labeled an item correctly or not.
What are the inputs to our model?
We kept it simple and used two input features: &lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The difficulty of the specific item &lt;/li&gt;
&lt;li&gt;The training set size used to train the model&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;These two features cover the two questions we are trying to answer:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;How important is training size on predictive performance?&lt;/li&gt;
&lt;li&gt;Does item difficulty affect predictive performance?&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;If we also model the interaction between these features, we can see if there are interesting changes as one or both features vary as well. 
So as a model gets more training data, does it learn the easy or hard items more quickly? &lt;/p&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;p&gt;Going in order based on the three questions raised above, we found that when we plotted the log odds of a model labeling an item correctly as a function of item difficulty and training set size:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;More training data leads to higher odds of correct labeling &lt;/li&gt;
&lt;li&gt;Easier items have higher odds of correct labeling &lt;/li&gt;
&lt;li&gt;As training data increases, the easy items get easier &lt;em&gt;faster&lt;/em&gt; than the hard items &lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The first point is straightforward and consistent with everything we know about machine learning.
More data equals better results. 
The second point looks like an obvious one, but there is a very important caveat here: those item difficulties were learned from a &lt;em&gt;human&lt;/em&gt; population.
The response patterns that we used to fit the IRT model were from Amazon Mechanical Turk workers.
So the difficulty parameters should be interpreted with respect to the human population.
The fact that those human difficulties are meaningful for neural networks is not obvious, but is in fact a very interesting finding.
Those networks think that hard things are hard too!
And the final point is, I think, very interesting. 
As these models are trained with more and more data, the rate of learning for the easy items increases faster than the rate of learning for the hard items. 
This is something that has parallels in human learning, where you develop a curriculum to teach the easy items first, then introduce the harder material afterwards.&lt;/p&gt;
&lt;p&gt;Now for the million dollar question: Who cares?
Well, I do. 
But other than me, this is an interesting new result that sheds some light on what is happening in these neural network models at the &lt;em&gt;item&lt;/em&gt; level, not just the aggregate test set level, which is where a lot of the analysis is.
We can see that there are characteristics of items that have an effect on whether a model will label the item correctly.
So we should think more about how models perform on specific items as opposed to how well models perform on large test sets. 
Test set accuracy is important, but it isn't the end all be all.&lt;/p&gt;</summary><category term="ml"></category><category term="nlp"></category><category term="irt"></category></entry><entry><title>A quick rant about language modeling.</title><link href="http://jplalor.github.io/openai.html" rel="alternate"></link><updated>2019-02-19T14:56:00-05:00</updated><author><name>John Lalor</name></author><id>tag:jplalor.github.io,2019-02-19:openai.html</id><summary type="html">&lt;p&gt;(I never thought I would write a title like that)&lt;/p&gt;
&lt;p&gt;Everyone is going crazy over the OpenAI thing. &lt;/p&gt;
&lt;p&gt;You can go crazy if you like, that's fine with me, seems to be what all the cool kids are doing these days.
I'd point you to &lt;a href="http://approximatelycorrect.com/2019/02/17/openai-trains-language-model-mass-hysteria-ensues/"&gt;Zachary Lipton's post&lt;/a&gt; for how I generally feel about the research aspect of this.
The short version is: this is a better version of very standard natural language processing. 
That's it.
It's also not going to destroy us all, so rest easy.&lt;/p&gt;
&lt;p&gt;But all of that being said, this raises some interesting questions about AI policy.
Specifically, it feels like we're currently in the middle of a moment where a whole lot of people &lt;em&gt;want&lt;/em&gt; AI to take over.
That sounds very dramatic, so let me unpack it. &lt;/p&gt;
&lt;p&gt;Let's start at the very beginning (a very good place to start).
Recall, dear reader, the ELIZA program (&lt;a href="https://www.masswerk.at/eliza/"&gt;click for an online version&lt;/a&gt;).
ELIZA was an early chatbot built to mimic a very specific sort of psychotherapist.
There is a lot written about the history of ELIZA, and it is fascinating.
Some of the subjects who interacted with ELIZA formed an emotional attachment to the program.
If you interact with ELIZA now you can see very quickly that not only is it a program, but it is one with pretty severe limitations.&lt;/p&gt;
&lt;p&gt;Which brings us to the new announcement.
This week, OpenAI announced that they had built a language model that was &lt;em&gt;very good.&lt;/em&gt;
The language model is essentially a better version of stuff that already exists and has existed for a very long time (again, see Zachary's post).
But there is huge concern right now that if this particular bit of research were to get into the wrong hands, bad things would happen.
This is silly.
But let's indulge ourselves for a minute.&lt;/p&gt;
&lt;p&gt;Imagine that you are a person (shouldn't be too hard).
You are consuming &lt;strong&gt;news&lt;/strong&gt; via your favorite app/dead tree/whatever.
(The fact that I bolded news is important).
As you read through a story, you may or may not check the byline to determine who wrote the piece.
Knowing the author can signal quality or trustworthiness if the author is good or trustworthy.
If you don't know the author, you can at least trust the news source.
So, if you finished your article and thought to yourself, "that was really well-written" and then I jumped out from behind you and yelled "Aha! But it was written by an AI!" what would you do?
Other than kick me out of your house (justifiable)?
You would probably go back and consider the article more closely.
You may even say "Hmm, I don't know if I trust an AI to write news, I should fire up Google dot com and see if this is being reported elsewhere."
But it's unlikely that you will say "OK!" and be done with it.
Why? 
Because you are a human! 
You are not a news-ingesting machine that simply takes in news uncritically.&lt;/p&gt;
&lt;p&gt;Your new skeptical approach to news written by an AI should really be your default method for reading the news, but that is a post for another time.&lt;/p&gt;
&lt;p&gt;Now, new scenario.
Imagine that you are a person (I know, I'm really making you work here).
You are reading some collection of words that are &lt;strong&gt;not news.&lt;/strong&gt;
This could be a novel, a poem, or (importantly) a commentary written &lt;em&gt;about&lt;/em&gt; something in the news (I hope we're all on the same page that these commentaries aren't news).
If I jumped out after you finished reading this and told you that it was written by an AI, what would you do?
My argument here is that your answer should be "I don't know and I don't really care. I was entertained."
AI-generated entertainment shouldn't be cause for concern.&lt;/p&gt;
&lt;p&gt;If some form of artificial intelligence (in this case, a language model) can create entertainment via text to the point where you can read it and enjoy it, that is a remarkable accomplishment that should be celebrated.&lt;/p&gt;
&lt;p&gt;If some form of artificial intelligence can create textual descriptions of news events, that is an even more impressive feat.&lt;/p&gt;
&lt;p&gt;If the AI can write what looks like news but has factual errors (even if the structure is good), then the text isn't news.
We already have defenses against this kind of not-news: the ability to do research, find facts, and make informed decisions about things.&lt;/p&gt;
&lt;p&gt;What OpenAI is saying with their lack of transparency over this whole thing is that this new language model is dangerous.
But I would ask the following: if this model is so good that we don't trust humans to read its output, has OpenAI just passed the Turing test?
Doubtful.
There simply is a model that does a better job of matching patterns in writing as determined by a very large corpus of writing.&lt;/p&gt;
&lt;p&gt;So what should we do moving forward?&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;OpenAI should release the model, or change their name&lt;/li&gt;
&lt;li&gt;Humans should regain some confidence &lt;/li&gt;
&lt;li&gt;You should change the locks in your house so I can't jump out from behind you anymore&lt;/li&gt;
&lt;li&gt;You should spend less time reading stuff on the internet&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The last point is most important.
Internet companies want you to spend time on the internet so that they can show you ads.
They have an incentive to provide &lt;em&gt;content&lt;/em&gt; in order to keep you on their pages.
They unfortunately do not currently have an incentive to provide you with &lt;em&gt;facts.&lt;/em&gt;
The more time you spend on the internet, the more content you see, the more ads you see, and the more money these companies get.
So, if they need more and more content, and fancy AI systems are writing top notch content now, then they will use said systems to reduce the cost of content.&lt;/p&gt;
&lt;p&gt;It's not clear if there will be an increased cost associated with the potentially-less-than-totally-true nature of the AI content.
But looking at fake news now, there isn't much cost associated with putting fake news online, so I don't see there being big costs to putting AI-fake-news online either.&lt;/p&gt;
&lt;p&gt;So if you want to prevent AI from taking over the world of online publishing, then don't read as much entertainment online.
Or if you are reading something online and you have your doubts as to whether it is true or not, do some digging! Find out for yourself.&lt;/p&gt;</summary></entry><entry><title>Item Response Theory for Natural Language Processing</title><link href="http://jplalor.github.io/emnlp-16.html" rel="alternate"></link><updated>2019-02-12T00:00:00-05:00</updated><author><name>John Lalor</name></author><id>tag:jplalor.github.io,2019-02-12:emnlp-16.html</id><summary type="html">&lt;p&gt;This post is meant as a companion to our EMNLP 2016 paper &lt;a href="https://arxiv.org/abs/1605.08889"&gt;"Building an Evaluation Scale using Item Response Theory"&lt;/a&gt;. 
It's quite a bit overdue, but hopefully this post will be useful to those who haven't seen IRT before.&lt;/p&gt;
&lt;h1&gt;Introduction&lt;/h1&gt;
&lt;p&gt;Let's start by thinking about the typical supervised machine learning setup. 
There is some training data, a held-out test set, and a machine learning model.
The goal is to use the training data to learn a model that performs well on the test set.
"Performs well"" is usually measured by some aggregate statistic such as accuracy, precision/recall, etc.
These aggregate statistics assume that each test set example is as important in determining model performance as every other test set example.
But what if that isn't the case?
What if certain examples are so easy that labelling them incorrectly is disastrous?
Or on the other hand, what if certain examples are so hard that no model labels them correctly (except your new deep deep deep network)?&lt;/p&gt;
&lt;p&gt;Characteristics such as difficulty are often used to assess humans in psychometrics, specifically a method known as Item Response Theory (IRT).
The high-level idea with IRT is that if you have enough test-takers providing answers to questions on a test ("items,"" hence the Item in IRT), you can learn latent parameters of the items as well as estimate a latent ability trait of the test-takers themselves.
IRT is popular in standardized tests such as the SAT and the GMAT.
It's used to assess the test-takers but also to select appropriate items for the tests themselves (if a test question is too easy, there's no need to include it).
What we wanted to do was take the IRT methodology and apply it to machine learning models, specifically models trained to do the natural language processing (NLP) natural language inference (NLI) task.&lt;/p&gt;
&lt;h1&gt;IRT&lt;/h1&gt;
&lt;p&gt;The key driver behind IRT is what's known as the Item Characteristic Curve (ICC).
Each item has an associated ICC, which can take certain forms depending on the IRT model that you're looking at.
A popular model (and the one we used in our paper) is the 3 Parameter Logistic (3PL) model:&lt;/p&gt;
&lt;div class="math"&gt;$$
p_{ij}(\theta_j) = c_i + \frac{1 - c_i}{1 + e^{-a_i(\theta_j - b_i)}}
$$&lt;/div&gt;
&lt;p&gt;
Here, &lt;span class="math"&gt;\(\theta_j\)&lt;/span&gt; is the latent ability parameter of test-taker &lt;span class="math"&gt;\(j\)&lt;/span&gt;, and &lt;span class="math"&gt;\(a_i\)&lt;/span&gt;, &lt;span class="math"&gt;\(b_i\)&lt;/span&gt;, and &lt;span class="math"&gt;\(c_i\)&lt;/span&gt; are item &lt;span class="math"&gt;\(i\)&lt;/span&gt;'s discriminatory, difficulty, and guessing parameters, respectively.
A typical IRT curve will look something like this:&lt;/p&gt;
&lt;p&gt;&lt;img alt="plot of chunk irtplot1" src="{static}/figure/emnlp16-irtplot1-1.png" /&gt;&lt;/p&gt;
&lt;p&gt;Our x-axis is &lt;span class="math"&gt;\(\theta_j\)&lt;/span&gt;, the latent ability parameter.
The y-axis is &lt;span class="math"&gt;\(p_{ij}(\theta_j)\)&lt;/span&gt;, the probability that an individual with a certain ability level will answer this item correctly.
The curve is monotonically increasing, which makes sense. 
As the ability of an individual increases, we expect that the probability of that individual answering correctly will also increase.
&lt;span class="math"&gt;\(a_i\)&lt;/span&gt;, the discriminatory parameter, represents the slope of the curve at its steepest point.
&lt;span class="math"&gt;\(a_i\)&lt;/span&gt; should be steep enough that in a relatively short range, there is a sizeable jump in &lt;span class="math"&gt;\(p_{ij}(\theta_j)\)&lt;/span&gt;, but shouldn't be so steep that the range is tiny.
An item with too steep of a slope is only useful in a very small ability range:&lt;/p&gt;
&lt;p&gt;&lt;img alt="plot of chunk irtplot2" src="{static}/figure/emnlp16-irtplot2-1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(b_i\)&lt;/span&gt;, the difficulty parameter, represents the halfway point between the minimum and maximum values of &lt;span class="math"&gt;\(p_{ij}(\theta_j)\)&lt;/span&gt;.
For a 3PL model, the minimum is &lt;span class="math"&gt;\(c_i\)&lt;/span&gt; and the maximum is &lt;span class="math"&gt;\(1\)&lt;/span&gt;.
Since &lt;span class="math"&gt;\(\theta\)&lt;/span&gt; is a unit Gaussian (&lt;span class="math"&gt;\(\theta_j \sim N(0, 1)\)&lt;/span&gt;), we want the value of &lt;span class="math"&gt;\(b_i\)&lt;/span&gt; to fall somewhere between &lt;span class="math"&gt;\(-3\)&lt;/span&gt; and &lt;span class="math"&gt;\(3\)&lt;/span&gt; in most cases, since that covers 99.7% of people.
The next two plots show "easy"" and "hard"" items where the difficulty parameters are &lt;span class="math"&gt;\(-2\)&lt;/span&gt; and &lt;span class="math"&gt;\(2\)&lt;/span&gt;, respectively:&lt;/p&gt;
&lt;p&gt;&lt;img alt="plot of chunk irtplot3" src="{static}/figure/emnlp16-irtplot3-1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="plot of chunk irtplot4" src="{static}/figure/emnlp16-irtplot4-1.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;span class="math"&gt;\(c_i\)&lt;/span&gt; is referred to as the guessing parameter. As you can see from the plots above, the lower asymptotes of the curves are not &lt;span class="math"&gt;\(0\)&lt;/span&gt;. In a three parameter model, there is an assumption that even at low levels of &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;, there is some non-zero probability that an individual will answer a question correctly (with for example a lucky guess). That is modeled by &lt;span class="math"&gt;\(c_i\)&lt;/span&gt;.&lt;/p&gt;
&lt;h1&gt;IRT for NLP&lt;/h1&gt;
&lt;p&gt;So how can we use IRT to help us in NLP? 
It's often the case that when you train and test your brand new machine learning model on an NLP dataset, the metric of interest is test set accuracy. 
If your model has a higher accuracy than the current state of the art in the literature, then your model becomes the new benchmark against which other models are evaluated. 
However, there is usually something missing in these evaluations: the question of the specific test set examples that were answered correctly. 
If your fancy new model has a high accuracy because it labeled a random sequence of examples correctly, that indicates very different performance than some other model that labeled items correctly according to their difficulty (i.e. labeled all easy examples correctly up to some difficulty threshold, then labeled all subsequent examples incorrectly). 
Having some notion of difficulty is important to distinguish between these two cases, which is where IRT comes in!&lt;/p&gt;
&lt;p&gt;We decided to test this out on the Stanford Natural Language Inference (SNLI) dataset. Natural language inference (NLI) is a popular task in NLP, where the goal is to determine if some sentence (premise) entails some other sentence (hypothesis). If the premise is true, does that mean that the hypothesis must be true (entailment), cannot be true (contradiction), or could be either (neutral)? You can imagine that there might be some ambiguity about certain examples having certain labels. So this seems like a perfect place to apply IRT to see if we can learn anything about the data and the high-performing models trained on the dataset.&lt;/p&gt;
&lt;h1&gt;Data Collection&lt;/h1&gt;
&lt;p&gt;In order to fit these IRT models, you need a lot of data. Specifically, you need a lot of answers to the same set of questions. If you ask a lot of people to take the same test, then grade each of their answers, the graded responses for each person is that person's response pattern. With a set of response patterns you can fit an IRT model to learn the latent parameters of the items as well as the latent &lt;span class="math"&gt;\(\theta\)&lt;/span&gt; for each of the test-takers.&lt;/p&gt;
&lt;p&gt;This goes against what is typically done when you are gathering data for machine learning models. Usually, you will collect between one and five labels for each example in your data set, and use a majority vote to determine the gold standard. Here, we used the crowdsourcing platform Amazon Mechanical Turk to gather 1000 labels for each example from our SNLI subset. So instead of asking a lot of Turkers for a few labels to a lot of examples, we asked them for a lot of labels for a small number of examples. Each Turker provided a label for each example, so we were able to grade the Turker responses to generate response patterns.&lt;/p&gt;
&lt;h1&gt;IRT Analysis&lt;/h1&gt;
&lt;p&gt;Fitting an IRT model is a cyclical process. At a high level, you fit your model, using your software package of choice (for R, the &lt;em&gt;mirt&lt;/em&gt; package is a good one). Then you check how well each item fits in with the learned model. Are there items where the discriminatory parameter is too large? Items like these aren't useful outside of a very specific range so they can be removed. Items where the parameter is too small are also removed, because they are not able to discriminate at all. Are there items that violate the local independence assumption? These are also removed.
Typically the items are removed one at a time, the model is re-fit, and the set of items is checked again. &lt;/p&gt;
&lt;h1&gt;Results&lt;/h1&gt;
&lt;p&gt;There are a number of results in the paper, but to boil it down into a single takeaway: specific data points are important! If you are testing your model on an easy dataset, then high accuracy scores aren't all that impressive, because everyone has a high accuracy. On the other hand, if you test on a difficult dataset, then lower accuracy scores may be indicative of higher latent &lt;span class="math"&gt;\(\theta\)&lt;/span&gt;, since the score is with respect to some population of test-takers. &lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Hopefully this was a useful introduction to IRT. I encourage you to check out the paper for much more detail. And feel free to email me if you have any questions or comments. The next post will discuss our EMNLP 2018 paper: Understanding Deep Learning Performance through an Examination of Test Set Difficulty: A Psychometric Case Study.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        fonts: [['STIX', 'TeX']]," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="ml"></category><category term="nlp"></category><category term="irt"></category></entry><entry><title>StatNLP: Essential Information Theory, Part 3</title><link href="http://jplalor.github.io/info-theory-part-3.html" rel="alternate"></link><updated>2018-03-28T00:00:00-04:00</updated><author><name>John Lalor</name></author><id>tag:jplalor.github.io,2018-03-28:info-theory-part-3.html</id><summary type="html">&lt;p&gt;After a bit of a hiatus, it's time to wrap up the Information Theory introduction. In this post I'm going to talk about Mutual Information and KL-Divergence. I'll look at why these two are important, how we get them from what we already know, and what we can do with them (with an example or two for good measure). After this post we can hit the ground running with the StatNLP book, woohoo!&lt;/p&gt;
&lt;h2&gt;Mutual Information&lt;/h2&gt;
&lt;p&gt;At the end of the previous post, we looked at the relationship between joint entropy and conditional entropy. Recall that &lt;span class="math"&gt;\(H(X,Y) = H(X) + H(Y \vert X)\)&lt;/span&gt;. In this formula, we can reverse &lt;span class="math"&gt;\(X\)&lt;/span&gt; and &lt;span class="math"&gt;\(Y\)&lt;/span&gt; to get &lt;span class="math"&gt;\(H(X,Y) = H(Y) + H(X \vert Y)\)&lt;/span&gt;. The two are equivalent. If we rearrange those formulas we can derive the formula for &lt;em&gt;mutual information:&lt;/em&gt;&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
H(X) + H(Y \vert X) &amp;amp;= H(Y) + H(X \vert Y) \\
H(X) - H(X \vert Y) &amp;amp;= H(Y) - H(Y \vert X) \\
&amp;amp;= I(X;Y)
\end{align}
$$&lt;/div&gt;
&lt;p&gt;
Mutual information describes the reduction in uncertainty of one random variable that you get if you know another random variable. For example if &lt;span class="math"&gt;\(X\)&lt;/span&gt; is a random variable indicating whether it is currently raining or not, and &lt;span class="math"&gt;\(Y\)&lt;/span&gt; is a random variable indicating whether the ground or not is wet, if you know that the ground is wet (&lt;span class="math"&gt;\(Y=1\)&lt;/span&gt;), that will reduce the amount of uncertainty in determining whether it is raining (&lt;span class="math"&gt;\(X\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;How do you calculate mutual information? From Equation 2.36 in StatNLP:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
I(X;Y) &amp;amp;= H(X) - H(X \vert Y) \\
&amp;amp;= H(X) + H(Y) - H(X,Y)  \textit{ by the chain rule} \\
&amp;amp;= \sum_x p(x) \log \frac{1}{p(x)} + \sum_y p(y) \log \frac{1}{p(y)} + \sum_{x,y} p(x,y) \log p(x,y) \\
&amp;amp;= \sum_{x,y} p(x,y) \log \frac{p(x,y)}{p(x)p(y)}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;In the case where two random variables are independent, then &lt;span class="math"&gt;\(I(X;Y) = 0\)&lt;/span&gt;. Why? Because &lt;span class="math"&gt;\(H(X \vert Y) = H(X)\)&lt;/span&gt;, so we have &lt;span class="math"&gt;\(I(X;Y) = H(X) - H(X) = 0\)&lt;/span&gt;. This makes sense since mutual information is measuring the reduction in uncertainty for one variable when you know another one. If you know &lt;span class="math"&gt;\(Y\)&lt;/span&gt;, but it is independent of &lt;span class="math"&gt;\(X\)&lt;/span&gt;, there is no reduction in uncertainty for &lt;span class="math"&gt;\(X\)&lt;/span&gt;. &lt;/p&gt;
&lt;h2&gt;KL-Divergence&lt;/h2&gt;
&lt;p&gt;The next definition is for Kullback-Leibler divergence, or KL-divergence. KL-divergence measures how far one probability distribution is from another:&lt;/p&gt;
&lt;div class="math"&gt;$$
D(p \vert \vert q) = \sum_{x \in X} p(x) \log \frac{p(x)}{q(x)}
$$&lt;/div&gt;
&lt;p&gt;
It's worth noting that KL-divergence is not a distance metric since it is not symmetric, &lt;span class="math"&gt;\(D(p \vert \vert q) \neq D(q \vert \vert p)\)&lt;/span&gt;. It's useful for determining how good of an estimate q is for p. And looking at our equation for mutual information, we see that it can be expressed as a KL-divergence: &lt;span class="math"&gt;\(I(X;Y) = D(p(x,y) \vert \vert p(x)p(y))\)&lt;/span&gt;. This shows us that mutual information is a way to quantify the dependence of a joint distribution. &lt;/p&gt;
&lt;h2&gt;Cross Entropy&lt;/h2&gt;
&lt;p&gt;Imagine that you have some random variable &lt;span class="math"&gt;\(X\)&lt;/span&gt; with some true probability distribution &lt;span class="math"&gt;\(p(x)\)&lt;/span&gt;. You don't know what &lt;span class="math"&gt;\(p\)&lt;/span&gt; is, but you have this other distribution &lt;span class="math"&gt;\(q\)&lt;/span&gt;, and you want to know how good of a job it does at approximating &lt;span class="math"&gt;\(p(x)\)&lt;/span&gt;. To answer this question requires &lt;em&gt;cross entropy:&lt;/em&gt; &lt;span class="math"&gt;\(H(X, q) = H(X) + D(p \vert \vert q)\)&lt;/span&gt;. Now wait a minute. The formula for cross entropy still requires that we know &lt;span class="math"&gt;\(p(x)\)&lt;/span&gt;. Let's rearrange some terms:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
H(X, q) &amp;amp;= H(X) + D(p \vert \vert q) \\
&amp;amp;= - \sum_x p(x) \log p(x) + \sum_x p(x) \log \frac{p(x)}{q(x)} \\
&amp;amp;= - \sum_x p(x) \log p(x) + \sum_x p(x) \log p(x) + \sum_x p(x) \log \frac{1}{q(x)} \\
&amp;amp;= \sum_x p(x) \frac{1}{\log q(x)} \\
&amp;amp;= \mathbb{E}_p [\log \frac{1}{q(x)}]
\end{align}
$$&lt;/div&gt;
&lt;p&gt;
We can calculate this if we know &lt;span class="math"&gt;\(q\)&lt;/span&gt;.&lt;/p&gt;
&lt;h2&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;These last few posts had a lot of definitions and math in them, but hopefully they are helpful for defining some key concepts in Information Theory. Entropy is a useful tool for machine learning and NLP, and upcoming posts will be using these concepts.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        fonts: [['STIX', 'TeX']]," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="ml"></category><category term="nlp"></category></entry><entry><title>StatNLP: Essential Information Theory, Part 2</title><link href="http://jplalor.github.io/info-theory-part-2.html" rel="alternate"></link><updated>2018-02-23T00:00:00-05:00</updated><author><name>John Lalor</name></author><id>tag:jplalor.github.io,2018-02-23:info-theory-part-2.html</id><summary type="html">&lt;p&gt;Welcome back! In the last post we started our discussion of Information Theory, and defined some key building blocks related to calculating information for a single random variable. This time we'll look at the relationships between two random variables, and what they can tell us (if anything) about the informativeness of each other.&lt;/p&gt;
&lt;h2&gt;Joint Entropy&lt;/h2&gt;
&lt;p&gt;The first thing we'll look at is &lt;strong&gt;joint entropy&lt;/strong&gt;. For two random variables, &lt;span class="math"&gt;\(X\)&lt;/span&gt; and &lt;span class="math"&gt;\(Y\)&lt;/span&gt;, the joint entropy between them is &lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
H(X, Y) &amp;amp;= - \sum_{x \in X} \sum_{y \in Y} p(x, y) \log p(x, y) \\
&amp;amp;= \sum_{x \in X} \sum_{y \in Y} p(x, y) \log \frac{1}{p(x, y)}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Joint entropy refers to the amount of information you would need to determine the values of two random variables.
As an example, we'll go back to coin flipping from last time.
Now, we have two independent coins, both of them unbiased (so &lt;span class="math"&gt;\(p(x=H) = p(x=T) = p(y=H) = p(y=T) = 0.5\)&lt;/span&gt;).&lt;/p&gt;
&lt;p&gt;The joint entropy for these two random variables is as follows (below the order for the variables is &lt;span class="math"&gt;\((x,y)\)&lt;/span&gt;, so &lt;span class="math"&gt;\(p(H,H)\)&lt;/span&gt; is really &lt;span class="math"&gt;\(p(x=H, y=H)\)&lt;/span&gt;:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
H(X, Y) &amp;amp;=  \sum_{x \in X} \sum_{y \in Y} p(x, y) \log \frac{1}{ p(x, y)} \\
&amp;amp;= p(H,H)\log \frac{1}{p(H,H)} + p(H,T)\log \frac{1}{p(H,T)} \\
&amp;amp;+ p(T,H)\log \frac{1}{p(T,H)} + p(T,T)\log \frac{1}{p(T,T)} \\
&amp;amp;= \frac{1}{4}\log 4 + \frac{1}{4}\log 4+ \frac{1}{4}\log 4+ \frac{1}{4}\log 4 \\
&amp;amp;= 2
\end{align}
$$&lt;/div&gt;
&lt;p&gt;
This should make sense, since we showed last time that the entropy of a single unbiased coin is 1 bit. If we have two coins, we then double our information.&lt;/p&gt;
&lt;h2&gt;Conditional Entropy&lt;/h2&gt;
&lt;p&gt;Conditional entropy is related to joint entropy. We're still dealing with two random variables, but with conditional entropy we're interested in how much information is gained &lt;em&gt;when we know one of the outcomes.&lt;/em&gt; &lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
H(Y \vert X) &amp;amp;= \sum_{x \in X} p(x) H(Y \vert X = x) \\
&amp;amp;= \sum_{x \in X} p(x) [\sum_{y \in Y} p(y \vert x) \log \frac{1}{p(y \vert x)}] \\
&amp;amp;= \sum_{x \in X} \sum_{y \in Y} p(x, y) log \frac{1}{p(y \vert x)}
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Ok, so what just happened? Let's take the previous set of equations one at a time. In the first line we define the conditional entropy as a weighted average of the conditional entropies of &lt;span class="math"&gt;\(Y\)&lt;/span&gt; given each possible value of &lt;span class="math"&gt;\(X\)&lt;/span&gt;. In the second line we just expand that out, using the definition of entropy. Finally, &lt;span class="math"&gt;\(p(x)p(y|x) = p(x,y)\)&lt;/span&gt; so we can rewrite the equation as in the third line.&lt;/p&gt;
&lt;p&gt;Joint and conditional entropy are closely related. With joint entropy, we are measuring the amount of information in two random variables. Conditional entropy we already know one of the two random variables, and so we're measuring how much additional information is in the other. We can also look at it mathematically, starting with the definition of joint entropy:&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
H(X, Y) &amp;amp;=  \sum_{x \in X} \sum_{y \in Y} p(x, y) \log \frac{1}{ p(x, y)} \\
&amp;amp;= \sum_{x \in X} \sum_{y \in Y} p(x,y) \log \frac{1}{ p(x) p(y\vert x)} \\
&amp;amp;= \sum_{x \in X} \sum_{y \in Y} p(x,y)[ \log \frac{1}{p(x)} + \log \frac{1}{p(y \vert x)}] \\
&amp;amp;= \sum_{x \in X} \sum_{y \in Y} p(x, y) \log \frac{1}{p(x)} + \sum_{x \in X} \sum_{y \in Y} p(x, y) \log \frac{1}{p(y \vert x)} \\
&amp;amp;= \sum_{x \in X} p(x) \log \frac{1}{p(x)} + \sum_{x \in X} \sum_{y \in Y} p(x, y) \log \frac{1}{p(y \vert x)} \\
&amp;amp;= H(X) + H(Y \vert X)
\end{align}
$$&lt;/div&gt;
&lt;p&gt;Let's walk through that. In eqn. 12, we rewrite &lt;span class="math"&gt;\(p(x,y)\)&lt;/span&gt; in the log. In eqn 13. we split that log product into a sum of logs. In eqn. 14 we move &lt;span class="math"&gt;\(p(x,y)\)&lt;/span&gt; into the sum, and in eqn. 15 we use the fact that &lt;span class="math"&gt;\(\sum_{y \in Y} p(x, y) = p(x)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;So to get the joint entropy of two random variables, you calculate the entropy of one, and add the conditional entropy of the other, given the first one. If the two random variables are independent, then &lt;span class="math"&gt;\(H(X, Y) = H(X) + H(Y)\)&lt;/span&gt;. We saw that above with our two coin example. If you swap all of the x's and y's in the above, you'll see that the order doesn't matter, and &lt;span class="math"&gt;\(H(X,Y) = H(X) + H(Y \vert X) = H(Y) + H(X \vert Y)\)&lt;/span&gt;&lt;/p&gt;
&lt;h2&gt;Wrapping Up&lt;/h2&gt;
&lt;p&gt;There were a lot of equations here, but hopefully they all make sense. We're still trying to measure information (as in standard entropy for a single random variable) but now we can look at the information relationship between pairs of random variables. Next time we'll look at two more advanced concepts: mutual information and KL-Divergence.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        fonts: [['STIX', 'TeX']]," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="ml"></category><category term="nlp"></category></entry><entry><title>StatNLP: Essential Information Theory, Part 1</title><link href="http://jplalor.github.io/info-theory-part-1.html" rel="alternate"></link><updated>2018-02-15T00:00:00-05:00</updated><author><name>John Lalor</name></author><id>tag:jplalor.github.io,2018-02-15:info-theory-part-1.html</id><summary type="html">&lt;p&gt;I'd like to blog regularly, but I often struggle to come up with topics. So what I'm going to do is blog my way through some textbooks, to work on my writing and also to make sure that I have the concepts in the books down pat. The first textbook in the series will be &lt;em&gt;Foundations of Statistical Natural Language Processing&lt;/em&gt; by Manning and Sch&amp;uuml;tze (which I'll refer to as StatNLP from here on out). And the first topic will be &lt;em&gt;Essential Information Theory&lt;/em&gt; (section 2.2 in the book). This first post will introduce entropy and provide a few examples.&lt;/p&gt;
&lt;h1&gt;Information Theory Basics&lt;/h1&gt;
&lt;p&gt;Information Theory as a field was developed by Claude Shannon in the 1940s. I won't go into too many details, but basically Shannon was working on a way to quantify how much information one could transmit through a channel that would inevitably lose some of the information due to some amount of noise. He introduced some key concepts that we'll define and visualize here. Information Theory as a whole is an active field, and we'll only scratch the surface here, but at the end of the series I'll provide some pointers for anyone interested in learning more.&lt;/p&gt;
&lt;h2&gt;Preliminaries&lt;/h2&gt;
&lt;p&gt;In this post we'll be looking at probabilities of random variables. We'll define a discrete random variable as a set of outcomes &lt;span class="math"&gt;\(X\)&lt;/span&gt;. Each potential outcome in &lt;span class="math"&gt;\(X\)&lt;/span&gt; has an associated probability: &lt;span class="math"&gt;\(p(X=x)\)&lt;/span&gt;. The &lt;em&gt;expectation&lt;/em&gt; (or &lt;em&gt;expected value&lt;/em&gt;) of &lt;span class="math"&gt;\(X\)&lt;/span&gt; is a weighted sum of the outcomes according to the probabilities:&lt;/p&gt;
&lt;div class="math"&gt;$$\mathbb{E}[X] = \sum_{x \in X} xp(x)$$&lt;/div&gt;
&lt;h2&gt;Entropy&lt;/h2&gt;
&lt;p&gt;One of the key pieces in Information Theory is entropy. Entropy is defined as the amount of &lt;em&gt;information&lt;/em&gt; in a random variable. The formula for entropy is &lt;/p&gt;
&lt;div class="math"&gt;$$H(X) = - \sum_{x \in X} p(x) \log p(x)$$&lt;/div&gt;
&lt;p&gt;Often times the logarithm in the formula is base 2, and the output is a measure of &lt;em&gt;bits&lt;/em&gt;. Sometimes you'll see the natural log (&lt;span class="math"&gt;\(\ln\)&lt;/span&gt;), and the output will be in &lt;em&gt;nats&lt;/em&gt;. You can also write this formula a few other ways. If you don't like the minus sign in the beginning there, you can move it in and use the reciprocal of the logarithm:&lt;/p&gt;
&lt;div class="math"&gt;$$H(X) = \sum_{x \in X} p(x) \log \frac{1}{p(x)}$$&lt;/div&gt;
&lt;p&gt;
&lt;span class="math"&gt;\(\log \frac{1}{p(x)}\)&lt;/span&gt; is known as the Shannon information content of an outcome (or information content for short). It tells you how much information you get for a specific outcome of a random variable. The previous formula looks a lot like an expectation. That's because it is! So we can rewrite the formula for entropy again as:&lt;/p&gt;
&lt;div class="math"&gt;$$H(X) = \mathbb{E}( \log \frac{1}{p(X)})$$&lt;/div&gt;
&lt;p&gt;Notice in this last formula that the &lt;span class="math"&gt;\(p(x)\)&lt;/span&gt; is now &lt;span class="math"&gt;\(p(X)\)&lt;/span&gt; (capital &lt;span class="math"&gt;\(X\)&lt;/span&gt; instead of lowercase &lt;span class="math"&gt;\(x\)&lt;/span&gt;). When we have a lowercase &lt;span class="math"&gt;\(x\)&lt;/span&gt;, we're looking for the probability of a specific value &lt;span class="math"&gt;\(x\)&lt;/span&gt; which is in the set of possible values &lt;span class="math"&gt;\(X\)&lt;/span&gt;. In the third equation, we're calculating the expectation of the random variable &lt;span class="math"&gt;\(X\)&lt;/span&gt;, and so we use &lt;span class="math"&gt;\(p(X)\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;So what do all of these equivalent formulas mean? When we're calculating entropy, what we're really calculating is the amount of information contained in a particular random variable. On one extreme, if we know everything about the random variable (if &lt;span class="math"&gt;\(p(x) = 1\)&lt;/span&gt; for one of the potential outcomes), then there is no information to be gained from the random variable. On the other extreme, if all of the outcomes are equally likely (as in a standard six-sided die) then there is a lot of information in the random variable. &lt;/p&gt;
&lt;p&gt;I always like to think about entropy in terms of flipping a coin. Let's say we have a completely unbiased coin, so that the probability of it landing on heads is equal to the probability of it landing on tails. Our random variable is still &lt;span class="math"&gt;\(X\)&lt;/span&gt;, and the possible values are &lt;span class="math"&gt;\(x = H\)&lt;/span&gt; and &lt;span class="math"&gt;\(x = T\)&lt;/span&gt;. The probability of each outcome is &lt;span class="math"&gt;\(p(x = H) = p(x = T) = 0.5\)&lt;/span&gt;.&lt;/p&gt;
&lt;p&gt;Let's plug this in to our formula for entropy (we'll use the 2nd formula above).&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
H(X) &amp;amp;= \sum_{x \in \{H, T\}}p(x) \log \frac{1}{p(x)} \\
 &amp;amp;= 0.5 * \log \frac{1}{0.5} + 0.5 * \log \frac{1}{0.5} \\
 &amp;amp;= 2*(0.5 \log 2) \\
 &amp;amp;= 1
\end{align}
$$&lt;/div&gt;
&lt;p&gt;So what this tells us is that every time we flip an unbiased coin, we get 1 bit of information. what if the coin was biased? For example, let's say that the probability of heads is &lt;span class="math"&gt;\(0.75\)&lt;/span&gt; and the probability of tails is &lt;span class="math"&gt;\(0.25\)&lt;/span&gt;. In that case when we calculate entropy we get&lt;/p&gt;
&lt;div class="math"&gt;$$
\begin{align}
H(X) &amp;amp;= \sum_{x \in \{H, T\}}p(x) \log \frac{1}{p(x)} \\
 &amp;amp;= 0.75 * \log \frac{1}{0.75} + 0.25 * \log \frac{1}{0.25} \\
 &amp;amp;\approx 0.81
\end{align}
$$&lt;/div&gt;
&lt;p&gt;
We get less information if we flip a biased coin. Why is that? Because there is less uncertainty in the outcome of the coin flip. If the coin is biased, then one side is more likely to come up than the other. In the case above, if the probability of getting heads is &lt;span class="math"&gt;\(0.75\)&lt;/span&gt;, then before you even flip it the odds are good that it will come up heads. So you don't get as much information as when the coin is unbiased, where there is more uncertainty (in fact, the maximum amount of uncertainty).&lt;/p&gt;
&lt;p&gt;Let's look at a plot of entropy as the bias of a coin changes.&lt;/p&gt;
&lt;p&gt;&lt;img alt="plot of chunk entropy_plot" src="{static}/figure/info_theory-entropy_plot-1.png" /&gt;&lt;/p&gt;
&lt;p&gt;As the plot shows, the more biased the coin is, the less information we gain when we flip it. Sometimes it helps to think about entropy in terms of being surprised. When we flip a coin biased to land on heads, we're less surprised when it does land on heads (lower entropy). But when a coin is unbiased, each flip is a surprise (high entropy).&lt;/p&gt;
&lt;h1&gt;Conclusion&lt;/h1&gt;
&lt;p&gt;Entropy is a key building block for Information Theory, and it is also very useful in Machine Learning and NLP (more in a later post). Next time we'll look at entropy for more than one random variable, and define joint entropy, conditional entropy, and (probably) KL-Divergence.&lt;/p&gt;
&lt;p&gt;As a last note, I wrote this post in RMarkdown, which was surprisingly easy to integrate with this site, which runs on Pelican. All I needed was the &lt;a href="https://github.com/getpelican/pelican-plugins/tree/master/rmd_reader"&gt;RMD Reader Pelican Plugin&lt;/a&gt;.&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        fonts: [['STIX', 'TeX']]," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="ml"></category><category term="nlp"></category></entry><entry><title>Dot Products and Vector Projections</title><link href="http://jplalor.github.io/vector-projections.html" rel="alternate"></link><updated>2015-10-20T14:58:00-04:00</updated><author><name>John Lalor</name></author><id>tag:jplalor.github.io,2015-10-20:vector-projections.html</id><summary type="html">&lt;p&gt;Every once in a while I'm going to write a post about something I learned in my Machine Learning course here at UMass. I'd like to do one post per lecture, but I'm late out of the gate, so it might be less frequent. These posts aren't intended to be thorough explanations of particular topics, but instead will be relatively high-level overviews, with a simple example to illustrate the concept. That's the plan anyway. Comments or corrections are welcome and encouraged.&lt;/p&gt;
&lt;p&gt;This post is about dot products and projections, mostly because they're really useful and came up early in lecture. The projection of a vector from one space to another can be very useful when trying to reduce the dimensionality of a set of vectors.&lt;/p&gt;
&lt;p&gt;Ok, quick pause for some background. What does that all mean?&lt;/p&gt;
&lt;p&gt;One way of thinking about data is as a collection of vectors. For example, if you are looking at a dataset where each entry is the height and weight of an individual, one of your vectors would look like this:&lt;/p&gt;
&lt;div class="math"&gt;$$v_a: \{70, 180\}$$&lt;/div&gt;
&lt;p&gt;Where &lt;span class="math"&gt;\(v_{a1}\)&lt;/span&gt; is individual a's height in inches and &lt;span class="math"&gt;\(v_{a2}\)&lt;/span&gt; is individual a's weight in pounds. This vector has a dimensionality of 2.&lt;/p&gt;
&lt;p&gt;Not all datasets will have dimensionality of 2. Many will have much higher dimensionality, which can make working with them difficult. One way of making life easier is attempting to take your high dimensional data and &lt;em&gt;project&lt;/em&gt; it onto a lower dimensional vector. In order to do this, we need to talk about dot products.&lt;/p&gt;
&lt;p&gt;Algebraically, the dot product of two vectors is the sum of the product of each pair of values in the vectors. So you take each pair of values from the two vectors, multiply them together, and add up all of those products.&lt;/p&gt;
&lt;div class="math"&gt;$$A\cdot B = \sum_{i=1}^n A_iB_i$$&lt;/div&gt;
&lt;p&gt;Knowing how to calculate a dot product, we can now project one vector onto another. In order to project vector B onto vector A, we take the dot product of B and A, and divide by the magnitude of A, which is really the square root of the dot product of A with itself, &lt;span class="math"&gt;\(\lvert\lvert A \rvert\rvert = \sqrt{A\cdot A}\)&lt;/span&gt;&lt;/p&gt;
&lt;div class="math"&gt;$$comp_ab = \frac{A\cdot B}{\lvert\lvert A \rvert\rvert}$$&lt;/div&gt;
&lt;p&gt;This will give a scalar value, which is called the component or scalar projection of B in the A direction. You can think of it as the length of the projection of vector B. To turn this into a vector projection, we multiply it by the unit vector for A: &lt;span class="math"&gt;\(\frac{A}{\lvert\lvert A\rvert\rvert}\)&lt;/span&gt;. The formula for the projection is therefore:&lt;/p&gt;
&lt;div class="math"&gt;$$proj_BA = \frac{A\cdot B}{\lvert\lvert A \rvert\rvert}\frac{A}{\lvert\lvert A\rvert\rvert}$$&lt;/div&gt;
&lt;p&gt;Let's look at an example to see how this all works. Consider two vectors:&lt;/p&gt;
&lt;div class="math"&gt;$$A = \{2, 4, 6\}$$&lt;/div&gt;
&lt;div class="math"&gt;$$B = \{10, 11, 12\}$$&lt;/div&gt;
&lt;p&gt;Let's project B onto A. First, we'll calculate the scalar projection:&lt;/p&gt;
&lt;div class="math"&gt;$$comp_AB = \frac{A\cdot B}{\lvert\lvert A\rvert\rvert}$$&lt;/div&gt;
&lt;div class="math"&gt;$$ = \frac{2 * 10 + 4 * 11 + 6 * 12}{\sqrt{2 * 2 + 4 * 4 + 6 * 6}} = 18.174$$&lt;/div&gt;
&lt;p&gt;So our scalar projection is 18.174. Now, we take that and multiply it by the A unit vector:&lt;/p&gt;
&lt;div class="math"&gt;$$proj_AB = \frac{A\cdot B}{\lvert\lvert A \rvert\rvert}\frac{A}{\lvert\lvert A\rvert\rvert}$$&lt;/div&gt;
&lt;div class="math"&gt;$$ = 18.174\frac{A}{\lvert\lvert A\rvert\rvert} = \{4.8571, 9.7143, 14.5714\}$$&lt;/div&gt;
&lt;p&gt;The result is the vector B &lt;em&gt;projected&lt;/em&gt; onto vector a.&lt;/p&gt;
&lt;p&gt;So there you have it. Dot products and projections. As you might have noticed, the vectors involved above were of the same length. But I thought we were going to project to lower dimensions? We will, we will. In order to do that we have to identify &lt;em&gt;basis vectors&lt;/em&gt; that identify the dimensions that we want to project to. That is a topic for a later post.&lt;/p&gt;
&lt;p&gt;References:&lt;/p&gt;
&lt;p&gt;&lt;a href="http://math.oregonstate.edu/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/dotprod/dotprod.html"&gt;http://math.oregonstate.edu/home/programs/undergrad/CalculusQuestStudyGuides/vcalc/dotprod/dotprod.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://en.wikipedia.org/wiki/Vector_projection"&gt;https://en.wikipedia.org/wiki/Vector_projection&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://mathworld.wolfram.com/DotProduct.html"&gt;http://mathworld.wolfram.com/DotProduct.html&lt;/a&gt;&lt;/p&gt;
&lt;script type="text/javascript"&gt;if (!document.getElementById('mathjaxscript_pelican_#%@#$@#')) {
    var align = "center",
        indent = "0em",
        linebreak = "false";

    if (false) {
        align = (screen.width &lt; 768) ? "left" : align;
        indent = (screen.width &lt; 768) ? "0em" : indent;
        linebreak = (screen.width &lt; 768) ? 'true' : linebreak;
    }

    var mathjaxscript = document.createElement('script');
    mathjaxscript.id = 'mathjaxscript_pelican_#%@#$@#';
    mathjaxscript.type = 'text/javascript';
    mathjaxscript.src = 'https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/latest.js?config=TeX-AMS-MML_HTMLorMML';

    var configscript = document.createElement('script');
    configscript.type = 'text/x-mathjax-config';
    configscript[(window.opera ? "innerHTML" : "text")] =
        "MathJax.Hub.Config({" +
        "    config: ['MMLorHTML.js']," +
        "    TeX: { extensions: ['AMSmath.js','AMSsymbols.js','noErrors.js','noUndefined.js'], equationNumbers: { autoNumber: 'none' } }," +
        "    jax: ['input/TeX','input/MathML','output/HTML-CSS']," +
        "    extensions: ['tex2jax.js','mml2jax.js','MathMenu.js','MathZoom.js']," +
        "    displayAlign: '"+ align +"'," +
        "    displayIndent: '"+ indent +"'," +
        "    showMathMenu: true," +
        "    messageStyle: 'normal'," +
        "    tex2jax: { " +
        "        inlineMath: [ ['\\\\(','\\\\)'] ], " +
        "        displayMath: [ ['$$','$$'] ]," +
        "        processEscapes: true," +
        "        preview: 'TeX'," +
        "    }, " +
        "    'HTML-CSS': { " +
        "        fonts: [['STIX', 'TeX']]," +
        "        styles: { '.MathJax_Display, .MathJax .mo, .MathJax .mi, .MathJax .mn': {color: 'inherit ! important'} }," +
        "        linebreaks: { automatic: "+ linebreak +", width: '90% container' }," +
        "    }, " +
        "}); " +
        "if ('default' !== 'default') {" +
            "MathJax.Hub.Register.StartupHook('HTML-CSS Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax['HTML-CSS'].FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
            "MathJax.Hub.Register.StartupHook('SVG Jax Ready',function () {" +
                "var VARIANT = MathJax.OutputJax.SVG.FONTDATA.VARIANT;" +
                "VARIANT['normal'].fonts.unshift('MathJax_default');" +
                "VARIANT['bold'].fonts.unshift('MathJax_default-bold');" +
                "VARIANT['italic'].fonts.unshift('MathJax_default-italic');" +
                "VARIANT['-tex-mathit'].fonts.unshift('MathJax_default-italic');" +
            "});" +
        "}";

    (document.body || document.getElementsByTagName('head')[0]).appendChild(configscript);
    (document.body || document.getElementsByTagName('head')[0]).appendChild(mathjaxscript);
}
&lt;/script&gt;</summary><category term="linalg"></category><category term="ml"></category></entry></feed>